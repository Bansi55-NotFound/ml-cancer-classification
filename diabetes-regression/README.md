# Diabetes Regression using Linear & Random Forest Regression

This project demonstrates a **regression problem** where the goal is to predict a **continuous disease progression score** using machine learning models and evaluate how close the predictions are to the actual values.

---

## ğŸ“Š Dataset

- **Dataset**: Diabetes dataset from `sklearn`
- **Problem Type**: Regression
- **Target Variable**: `target` (numeric disease progression score)
- **Features**: Medical measurements such as BMI, blood pressure, etc.
- Dataset is small, clean, and suitable for learning regression fundamentals.

---

## ğŸ¯ Problem Statement

Predict the disease progression score based on multiple medical features and evaluate the model performance using regression metrics.

---

## ğŸ¤– Models Used

### 1ï¸âƒ£ Linear Regression (Baseline Model)
- Assumes a **linear relationship** between features and target
- Used as a **baseline** model
- Requires **feature scaling**
- Simple and interpretable

### 2ï¸âƒ£ Random Forest Regressor
- Ensemble model using **multiple decision trees**
- Captures **non-linear relationships**
- Does **not require feature scaling**
- Final prediction is the **average of predictions from all trees**

---

## ğŸ”„ Approach

1. Load and explore the dataset  
2. Separate features (`X`) and target (`y`)  
3. Split data into training (80%) and testing (20%) sets  
4. Train models:
   - Linear Regression (with StandardScaler)
   - Random Forest Regressor (without scaling)
5. Evaluate models on unseen test data  

---

## ğŸ“ Evaluation Metrics

Since this is a **regression problem**, the following metrics are used:

- **MSE (Mean Squared Error)** â€“ Average squared prediction error  
- **RMSE (Root Mean Squared Error)** â€“ Average prediction error in original units  
- **RÂ² Score** â€“ Proportion of variance in the target explained by the model  

---

## ğŸ“ˆ Results

| Model | RMSE | RÂ² |
|------|------|----|
| Linear Regression | ~53.85 | ~0.45 |
| Random Forest Regressor | ~54.69 | ~0.49 |

---

## ğŸ§  Key Learnings

- Regression predicts **continuous numeric values**, not classes  
- Predictions are **approximate**, not exact  
- **RMSE** tells how wrong the model is on average  
- **RÂ²** shows how well the model explains data variation  
- More complex models do **not always significantly reduce prediction error**, even if they capture patterns better  

---

## âœ… Conclusion

Random Forest Regressor slightly improves the **RÂ² score**, indicating better capture of non-linear relationships, while the **RMSE remains similar** to Linear Regression. This shows that increased model complexity does not always lead to large improvements in prediction accuracy.

---

## ğŸš€ Future Improvements

- Hyperparameter tuning for Random Forest  
- Feature importance analysis  
- Trying Gradient Boosting models  

---

## ğŸ“Œ Tech Stack

- Python  
- pandas  
- NumPy  
- scikit-learn  
