{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5fd4c52-f4a3-4fd2-83e6-8c5795ffd990",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\datasets\\_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "# STEP 0 ‚Äî Import Basic Libraries\n",
    "import pandas as pd\n",
    "\n",
    "# STEP 1 - Load data set (heart disease)\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "data = fetch_openml(name=\"heart-disease\", version=1, as_frame=True)\n",
    "df = data.frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db47f27d-a353-4ecc-b027-4ece3d2a06ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42db6e0e-ac9b-4e64-8d51-4c8b6cc56814",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 2 - separate feature X and Y\n",
    "X = df.drop(\"target\", axis=1)\n",
    "Y = df[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f5932cc-b00f-4a35-9f4e-1077fa5d4689",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 3 - Train/Test split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77f43143-5d99-4f35-8bb0-0eaf68cf6171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((242, 13), (61, 13))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7fd650b3-a1e7-455b-8821-4715e547897e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'n_estimators=100\\nThis tells the model:\\n\\n‚ÄúBuild 100 decision trees in the forest.‚Äù\\n\\nWhy this matters:\\n\\nMore trees ‚Üí more stable predictions\\n\\nFewer trees ‚Üí faster but less reliable\\n\\n100 is:\\n\\nA safe default\\n\\nWidely used in practice'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#step 4 - import randomForest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=42\n",
    "    )\n",
    "\n",
    "\"\"\"n_estimators=100\n",
    "This tells the model:\n",
    "\n",
    "‚ÄúBuild 100 decision trees in the forest.‚Äù\n",
    "\n",
    "Why this matters:\n",
    "\n",
    "More trees ‚Üí more stable predictions\n",
    "\n",
    "Fewer trees ‚Üí faster but less reliable\n",
    "\n",
    "100 is:\n",
    "\n",
    "A safe default\n",
    "\n",
    "Widely used in practice\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e42a863-4460-4965-a81b-1911bc611430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What Happens in This Step (Simple)\\nWhen you run .fit():\\n\\nThe model:\\n\\nTakes X_train (features)\\nTakes y_train (correct answers)\\n\\nBuilds 100 decision trees\\nEach tree:\\nSees slightly different data\\nLearns different rules\\nThe forest stores all learned trees\\n\\nAfter this:\\nThe model is trained and ready to make predictions.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#step 5 - train randome forest model\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "\"\"\"What Happens in This Step (Simple)\n",
    "When you run .fit():\n",
    "\n",
    "The model:\n",
    "\n",
    "Takes X_train (features)\n",
    "Takes y_train (correct answers)\n",
    "\n",
    "Builds 100 decision trees\n",
    "Each tree:\n",
    "Sees slightly different data\n",
    "Learns different rules\n",
    "The forest stores all learned trees\n",
    "\n",
    "After this:\n",
    "The model is trained and ready to make predictions.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e7823a5-c99c-48b2-8d12-bc7e7ca18ae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 1, 1, 1, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step 6 - make predictions\n",
    "y_pred_rf = rf.predict(x_test)\n",
    "y_pred_rf[:10]\n",
    "\n",
    "\"\"\"What‚Äôs happening internally (simple)\n",
    "\n",
    "For each patient in X_test:\n",
    "\n",
    "Each of the 100 trees makes a prediction\n",
    "\n",
    "Trees vote\n",
    "\n",
    "Majority vote becomes the final class (0 or 1)\n",
    "\n",
    "No probabilities yet ‚Äî just final decisions.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "662c9e18-cf9c-427e-a28a-59860364f6e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[24,  5],\n",
       "       [ 5, 27]], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step 7 evaluate randome forest model\n",
    "\n",
    "#step 7.1 confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred_rf)\n",
    "cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35f2d09d-7c29-4281-b64a-8308da46f5e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8360655737704918"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step 7.2 accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred_rf)\n",
    "\n",
    "\"\"\"What this means\n",
    "\n",
    "Out of all test patients, the Random Forest predicted about 84% correctly.\n",
    "\n",
    "Compare with Logistic Regression\n",
    "\n",
    "Logistic Regression accuracy ‚âà 85%\n",
    "\n",
    "Random Forest accuracy ‚âà 84%\n",
    "\n",
    "üëâ So accuracy is slightly lower for Random Forest here.\n",
    "\n",
    "That‚Äôs totally fine ‚Äî accuracy alone doesn‚Äôt decide the better model.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12833702-8a5b-451c-b12d-30c2d66616d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84375"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#step 7.3 recall\n",
    "from sklearn.metrics import recall_score\n",
    "recall_score(y_test,y_pred_rf)\n",
    "\n",
    "\"\"\"Medical Insight (Important)\n",
    "\n",
    "Random Forest did not improve recall here\n",
    "\n",
    "Missing disease cases is still 5\n",
    "\n",
    "So from a medical safety point of view:\n",
    "\n",
    "Random Forest ‚âà Logistic Regression\n",
    "\n",
    "This tells us something important:\n",
    "\n",
    "Changing the model alone doesn‚Äôt always improve recall.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d59e59cb-ac0a-4209-a20b-0fdd3f77075e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84375"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step 7.4 precision\n",
    "from sklearn.metrics import precision_score\n",
    "precision_score(y_test, y_pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769ac5a0-9b13-443a-a0d2-475a26dc27fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "| Metric              | Logistic Regression | Random Forest |\n",
    "| ------------------- | ------------------- | ------------- |\n",
    "| Accuracy            | ~85%                | ~84%          |\n",
    "| Recall (Disease)    | ~84%                | ~84%          |\n",
    "| Precision (Disease) | ~87%                | ~84%          |\n",
    "| Missed disease (FN) | 5                   | 5             |\n",
    "\n",
    "Random Forest did NOT outperform Logistic Regression here.\n",
    "\n",
    "Why?\n",
    "\n",
    "Dataset is small\n",
    "\n",
    "Relationships may be mostly linear\n",
    "\n",
    "Default Random Forest settings\n",
    "\n",
    "No threshold tuning\n",
    "\n",
    "This is a valuable real-world lesson:\n",
    "\n",
    "A more complex model is not always better.\n",
    "\n",
    "-----------------------------------\n",
    "\n",
    "Medical Perspective (Decision)\n",
    "\n",
    "If your goal is:\n",
    "\n",
    "Simple & interpretable ‚Üí Logistic Regression ‚úÖ\n",
    "\n",
    "Same recall, fewer false alarms ‚Üí Logistic Regression ‚úÖ\n",
    "\n",
    "So in this case:\n",
    "\n",
    "Logistic Regression is the better baseline model.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2177f05a-5d5d-423e-a023-a6650c52b632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05, 0.62, 0.55, 0.14, 0.79])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"FINAL STEP ‚Äî ROC & AUC (Random Forest)\n",
    "üß† Reminder (1 line)\n",
    "\n",
    "ROC ‚Üí how performance changes with threshold\n",
    "\n",
    "AUC ‚Üí how well the model separates classes overall\"\"\"\n",
    "\n",
    "#We use predict_proba to get how likely each patient has heart disease, and we select the probability of class 1 to calculate ROC and AUC.\n",
    "\n",
    "#STEP 8.1 ‚Äî Get Prediction Probabilities\n",
    "\n",
    "y_prob_rf = rf.predict_proba(x_test)\n",
    "\n",
    "y_prob_rf_pos = y_prob_rf[:, 1]\n",
    "y_prob_rf_pos[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b9b0a6e-c87c-4488-b00e-2cc46a416cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9202586206896551"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#step caculate auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "auc_rf = roc_auc_score(y_test, y_prob_rf_pos)\n",
    "auc_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f745f909-c0da-4e8e-a1ce-5ed21af55627",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"What this means (simple)\n",
    "\n",
    "The Random Forest has very good class separation, but slightly worse than Logistic Regression.\n",
    "\n",
    "Recall:\n",
    "\n",
    "Logistic Regression AUC ‚âà 0.93\n",
    "\n",
    "Random Forest AUC ‚âà 0.92\n",
    "\n",
    "So:\n",
    "\n",
    "Both models are strong\n",
    "\n",
    "Logistic Regression is marginally better here\n",
    "\n",
    "---------------------------------------------------\n",
    "\n",
    "On THIS dataset:\n",
    "\n",
    "Logistic Regression wins\n",
    "\n",
    "Random Forest does not add value yet\n",
    "\n",
    "Why this happens:\n",
    "\n",
    "Dataset is small\n",
    "\n",
    "Patterns are mostly linear\n",
    "\n",
    "Random Forest defaults (no tuning)\n",
    "\n",
    "Same threshold (0.5)\n",
    "\n",
    "This is a real ML lesson:\n",
    "\n",
    "More complex ‚â† always better\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
